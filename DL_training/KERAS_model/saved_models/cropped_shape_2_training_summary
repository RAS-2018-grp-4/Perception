##########    LOADING DATA     ##########
##########    Star , Label : 6      ##########
##########    Nothing , Label : 7      ##########
##########    Cylinder , Label : 2      ##########
##########    Cube , Label : 1      ##########
##########    Hollow Cube , Label : 3      ##########
##########    Ball , Label : 0      ##########
##########    Cross , Label : 4      ##########
##########    Triangle , Label : 5      ##########
2018-12-03 02:05:30.100437: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-03 02:05:30.194234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-03 02:05:30.194722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties:
name: GeForce GTX 1060 major: 6 minor: 1 memoryClockRate(GHz): 1.733
pciBusID: 0000:01:00.0
totalMemory: 5.94GiB freeMemory: 5.50GiB
2018-12-03 02:05:30.194751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2018-12-03 02:05:30.405973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-03 02:05:30.406005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0
2018-12-03 02:05:30.406032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N
2018-12-03 02:05:30.406218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5265 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 32, 32, 32)        896
_________________________________________________________________
activation_1 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
batch_normalization_1 (Batch (None, 32, 32, 32)        128
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248
_________________________________________________________________
activation_2 (Activation)    (None, 32, 32, 32)        0
_________________________________________________________________
batch_normalization_2 (Batch (None, 32, 32, 32)        128
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0
_________________________________________________________________
dropout_1 (Dropout)          (None, 16, 16, 32)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496
_________________________________________________________________
activation_3 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
batch_normalization_3 (Batch (None, 16, 16, 64)        256
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928
_________________________________________________________________
activation_4 (Activation)    (None, 16, 16, 64)        0
_________________________________________________________________
batch_normalization_4 (Batch (None, 16, 16, 64)        256
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0
_________________________________________________________________
dropout_2 (Dropout)          (None, 8, 8, 64)          0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856
_________________________________________________________________
activation_5 (Activation)    (None, 8, 8, 128)         0
_________________________________________________________________
batch_normalization_5 (Batch (None, 8, 8, 128)         512
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584
_________________________________________________________________
activation_6 (Activation)    (None, 8, 8, 128)         0
_________________________________________________________________
batch_normalization_6 (Batch (None, 8, 8, 128)         512
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0
_________________________________________________________________
dropout_3 (Dropout)          (None, 4, 4, 128)         0
_________________________________________________________________
flatten_1 (Flatten)          (None, 2048)              0
_________________________________________________________________
dense_1 (Dense)              (None, 8)                 16392
=================================================================
Total params: 305,192
Trainable params: 304,296
Non-trainable params: 896
_________________________________________________________________
Epoch 1/100
34/34 [==============================] - 3s 79ms/step - loss: 2.3941 - acc: 0.4181 - val_loss: 1.1906 - val_acc: 0.5855
Epoch 2/100
34/34 [==============================] - 1s 34ms/step - loss: 1.3785 - acc: 0.5409 - val_loss: 2.3521 - val_acc: 0.5677
Epoch 3/100
34/34 [==============================] - 1s 30ms/step - loss: 1.1383 - acc: 0.6056 - val_loss: 2.3840 - val_acc: 0.5530
Epoch 4/100
34/34 [==============================] - 1s 31ms/step - loss: 1.0851 - acc: 0.6285 - val_loss: 1.3606 - val_acc: 0.6432
Epoch 5/100
34/34 [==============================] - 1s 31ms/step - loss: 0.9751 - acc: 0.6549 - val_loss: 0.9431 - val_acc: 0.6873
Epoch 6/100
34/34 [==============================] - 1s 28ms/step - loss: 0.8659 - acc: 0.6837 - val_loss: 0.9581 - val_acc: 0.7062
Epoch 7/100
34/34 [==============================] - 1s 27ms/step - loss: 0.8296 - acc: 0.6907 - val_loss: 0.7205 - val_acc: 0.7712
Epoch 8/100
34/34 [==============================] - 1s 28ms/step - loss: 0.7883 - acc: 0.7022 - val_loss: 0.6368 - val_acc: 0.7576
Epoch 9/100
34/34 [==============================] - 1s 27ms/step - loss: 0.7354 - acc: 0.7174 - val_loss: 0.7189 - val_acc: 0.7566
Epoch 10/100
34/34 [==============================] - 1s 27ms/step - loss: 0.7173 - acc: 0.7318 - val_loss: 0.6673 - val_acc: 0.7671
Epoch 11/100
34/34 [==============================] - 1s 31ms/step - loss: 0.6496 - acc: 0.7575 - val_loss: 0.6374 - val_acc: 0.7639
Epoch 12/100
34/34 [==============================] - 1s 31ms/step - loss: 0.6297 - acc: 0.7537 - val_loss: 0.5523 - val_acc: 0.7796
Epoch 13/100
34/34 [==============================] - 1s 30ms/step - loss: 0.6465 - acc: 0.7601 - val_loss: 0.5016 - val_acc: 0.8290
Epoch 14/100
34/34 [==============================] - 1s 29ms/step - loss: 0.5983 - acc: 0.7656 - val_loss: 0.7185 - val_acc: 0.7597
Epoch 15/100
34/34 [==============================] - 1s 29ms/step - loss: 0.6184 - acc: 0.7679 - val_loss: 0.3890 - val_acc: 0.8468
Epoch 16/100
34/34 [==============================] - 1s 28ms/step - loss: 0.6169 - acc: 0.7799 - val_loss: 0.4645 - val_acc: 0.8258
Epoch 17/100
34/34 [==============================] - 1s 28ms/step - loss: 0.5420 - acc: 0.7912 - val_loss: 0.4569 - val_acc: 0.8227
Epoch 18/100
34/34 [==============================] - 1s 28ms/step - loss: 0.5482 - acc: 0.7895 - val_loss: 0.4721 - val_acc: 0.8248
Epoch 19/100
34/34 [==============================] - 1s 29ms/step - loss: 0.5287 - acc: 0.8007 - val_loss: 0.3739 - val_acc: 0.8531
Epoch 20/100
34/34 [==============================] - 1s 28ms/step - loss: 0.4873 - acc: 0.8056 - val_loss: 0.4399 - val_acc: 0.8447
Epoch 21/100
34/34 [==============================] - 1s 28ms/step - loss: 0.4814 - acc: 0.8303 - val_loss: 0.5125 - val_acc: 0.8017
Epoch 22/100
34/34 [==============================] - 1s 28ms/step - loss: 0.4534 - acc: 0.8248 - val_loss: 0.3625 - val_acc: 0.8636
Epoch 23/100
34/34 [==============================] - 1s 28ms/step - loss: 0.4807 - acc: 0.8249 - val_loss: 0.4103 - val_acc: 0.8395
Epoch 24/100
34/34 [==============================] - 1s 29ms/step - loss: 0.5153 - acc: 0.8124 - val_loss: 0.3682 - val_acc: 0.8604
Epoch 25/100
34/34 [==============================] - 1s 28ms/step - loss: 0.4215 - acc: 0.8459 - val_loss: 0.3856 - val_acc: 0.8562
Epoch 26/100
34/34 [==============================] - 1s 27ms/step - loss: 0.4435 - acc: 0.8384 - val_loss: 0.3682 - val_acc: 0.8573
Epoch 27/100
34/34 [==============================] - 1s 28ms/step - loss: 0.4238 - acc: 0.8493 - val_loss: 0.3764 - val_acc: 0.8468
Epoch 28/100
34/34 [==============================] - 1s 28ms/step - loss: 0.4206 - acc: 0.8427 - val_loss: 0.5153 - val_acc: 0.8269
Epoch 29/100
34/34 [==============================] - 1s 28ms/step - loss: 0.4384 - acc: 0.8516 - val_loss: 0.3604 - val_acc: 0.8573
Epoch 30/100
34/34 [==============================] - 1s 28ms/step - loss: 0.4445 - acc: 0.8433 - val_loss: 0.3531 - val_acc: 0.8709
Epoch 31/100
34/34 [==============================] - 1s 28ms/step - loss: 0.3754 - acc: 0.8603 - val_loss: 0.3830 - val_acc: 0.8636
Epoch 32/100
34/34 [==============================] - 1s 28ms/step - loss: 0.3851 - acc: 0.8685 - val_loss: 0.3548 - val_acc: 0.8615
Epoch 33/100
34/34 [==============================] - 1s 29ms/step - loss: 0.3912 - acc: 0.8646 - val_loss: 0.3708 - val_acc: 0.8688
Epoch 34/100
34/34 [==============================] - 1s 28ms/step - loss: 0.3393 - acc: 0.8842 - val_loss: 0.2914 - val_acc: 0.9035
Epoch 35/100
34/34 [==============================] - 1s 27ms/step - loss: 0.3806 - acc: 0.8690 - val_loss: 0.3496 - val_acc: 0.8814
Epoch 36/100
34/34 [==============================] - 1s 27ms/step - loss: 0.3828 - acc: 0.8732 - val_loss: 0.2839 - val_acc: 0.9108
Epoch 37/100
34/34 [==============================] - 1s 32ms/step - loss: 0.3617 - acc: 0.8701 - val_loss: 0.3601 - val_acc: 0.8951
Epoch 38/100
34/34 [==============================] - 1s 30ms/step - loss: 0.3606 - acc: 0.8789 - val_loss: 0.3345 - val_acc: 0.8877
Epoch 39/100
34/34 [==============================] - 1s 31ms/step - loss: 0.3681 - acc: 0.8708 - val_loss: 0.2780 - val_acc: 0.8993
Epoch 40/100
34/34 [==============================] - 1s 31ms/step - loss: 0.3118 - acc: 0.8906 - val_loss: 0.2799 - val_acc: 0.9171
Epoch 41/100
34/34 [==============================] - 1s 28ms/step - loss: 0.3190 - acc: 0.8897 - val_loss: 0.2871 - val_acc: 0.9056
Epoch 42/100
34/34 [==============================] - 1s 27ms/step - loss: 0.3146 - acc: 0.8876 - val_loss: 0.3404 - val_acc: 0.9003
Epoch 43/100
34/34 [==============================] - 1s 27ms/step - loss: 0.3186 - acc: 0.8965 - val_loss: 0.2653 - val_acc: 0.9171
Epoch 44/100
34/34 [==============================] - 1s 27ms/step - loss: 0.3041 - acc: 0.9053 - val_loss: 0.3422 - val_acc: 0.8888
Epoch 45/100
34/34 [==============================] - 1s 27ms/step - loss: 0.3064 - acc: 0.9043 - val_loss: 0.2924 - val_acc: 0.9056
Epoch 46/100
34/34 [==============================] - 1s 27ms/step - loss: 0.2987 - acc: 0.9090 - val_loss: 0.2037 - val_acc: 0.9465
Epoch 47/100
34/34 [==============================] - 1s 30ms/step - loss: 0.2802 - acc: 0.9113 - val_loss: 0.2571 - val_acc: 0.9349
Epoch 48/100
34/34 [==============================] - 1s 30ms/step - loss: 0.2734 - acc: 0.9145 - val_loss: 0.2345 - val_acc: 0.9307
Epoch 49/100
34/34 [==============================] - 1s 29ms/step - loss: 0.2653 - acc: 0.9233 - val_loss: 0.2524 - val_acc: 0.9381
Epoch 50/100
34/34 [==============================] - 1s 28ms/step - loss: 0.2696 - acc: 0.9149 - val_loss: 0.2373 - val_acc: 0.9234
Epoch 51/100
34/34 [==============================] - 1s 30ms/step - loss: 0.2746 - acc: 0.9118 - val_loss: 0.2104 - val_acc: 0.9423
Epoch 52/100
34/34 [==============================] - 1s 28ms/step - loss: 0.2598 - acc: 0.9186 - val_loss: 0.1743 - val_acc: 0.9601
Epoch 53/100
34/34 [==============================] - 1s 28ms/step - loss: 0.2581 - acc: 0.9263 - val_loss: 0.1968 - val_acc: 0.9475
Epoch 54/100
34/34 [==============================] - 1s 28ms/step - loss: 0.2562 - acc: 0.9278 - val_loss: 0.1978 - val_acc: 0.9549
Epoch 55/100
34/34 [==============================] - 1s 27ms/step - loss: 0.2456 - acc: 0.9370 - val_loss: 0.2162 - val_acc: 0.9307
Epoch 56/100
34/34 [==============================] - 1s 29ms/step - loss: 0.2302 - acc: 0.9362 - val_loss: 0.1602 - val_acc: 0.9664
Epoch 57/100
34/34 [==============================] - 1s 28ms/step - loss: 0.2557 - acc: 0.9273 - val_loss: 0.2454 - val_acc: 0.9507
Epoch 58/100
34/34 [==============================] - 1s 29ms/step - loss: 0.2483 - acc: 0.9341 - val_loss: 0.1509 - val_acc: 0.9696
Epoch 59/100
34/34 [==============================] - 1s 28ms/step - loss: 0.2146 - acc: 0.9422 - val_loss: 0.2222 - val_acc: 0.9391
Epoch 60/100
34/34 [==============================] - 1s 27ms/step - loss: 0.2327 - acc: 0.9377 - val_loss: 0.1420 - val_acc: 0.9738
Epoch 61/100
34/34 [==============================] - 1s 27ms/step - loss: 0.2182 - acc: 0.9400 - val_loss: 0.1410 - val_acc: 0.9759
Epoch 62/100
34/34 [==============================] - 1s 28ms/step - loss: 0.2083 - acc: 0.9487 - val_loss: 0.1557 - val_acc: 0.9664
Epoch 63/100
34/34 [==============================] - 1s 27ms/step - loss: 0.2276 - acc: 0.9370 - val_loss: 0.2192 - val_acc: 0.9412
Epoch 64/100
34/34 [==============================] - 1s 28ms/step - loss: 0.2229 - acc: 0.9394 - val_loss: 0.1481 - val_acc: 0.9706
Epoch 65/100
34/34 [==============================] - 1s 27ms/step - loss: 0.2276 - acc: 0.9414 - val_loss: 0.1551 - val_acc: 0.9685
Epoch 66/100
34/34 [==============================] - 1s 28ms/step - loss: 0.1931 - acc: 0.9554 - val_loss: 0.1437 - val_acc: 0.9727
Epoch 67/100
34/34 [==============================] - 1s 27ms/step - loss: 0.2161 - acc: 0.9452 - val_loss: 0.1840 - val_acc: 0.9580
Epoch 68/100
34/34 [==============================] - 1s 27ms/step - loss: 0.2016 - acc: 0.9482 - val_loss: 0.1823 - val_acc: 0.9622
Epoch 69/100
34/34 [==============================] - 1s 28ms/step - loss: 0.2015 - acc: 0.9480 - val_loss: 0.1471 - val_acc: 0.9654
Epoch 70/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1861 - acc: 0.9575 - val_loss: 0.1331 - val_acc: 0.9748
Epoch 71/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1921 - acc: 0.9503 - val_loss: 0.1322 - val_acc: 0.9748
Epoch 72/100
34/34 [==============================] - 1s 31ms/step - loss: 0.1858 - acc: 0.9609 - val_loss: 0.1241 - val_acc: 0.9790
Epoch 73/100
34/34 [==============================] - 1s 30ms/step - loss: 0.1806 - acc: 0.9581 - val_loss: 0.2719 - val_acc: 0.9391
Epoch 74/100
34/34 [==============================] - 1s 32ms/step - loss: 0.1765 - acc: 0.9613 - val_loss: 0.1381 - val_acc: 0.9738
Epoch 75/100
34/34 [==============================] - 1s 31ms/step - loss: 0.1793 - acc: 0.9585 - val_loss: 0.1940 - val_acc: 0.9633
Epoch 76/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1817 - acc: 0.9589 - val_loss: 0.1362 - val_acc: 0.9738
Epoch 77/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1570 - acc: 0.9626 - val_loss: 0.1266 - val_acc: 0.9727
Epoch 78/100
34/34 [==============================] - 1s 28ms/step - loss: 0.1397 - acc: 0.9747 - val_loss: 0.1173 - val_acc: 0.9832
Epoch 79/100
34/34 [==============================] - 1s 31ms/step - loss: 0.1378 - acc: 0.9787 - val_loss: 0.1139 - val_acc: 0.9843
Epoch 80/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1430 - acc: 0.9713 - val_loss: 0.1271 - val_acc: 0.9780
Epoch 81/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1269 - acc: 0.9812 - val_loss: 0.1281 - val_acc: 0.9769
Epoch 82/100
34/34 [==============================] - 1s 30ms/step - loss: 0.1426 - acc: 0.9751 - val_loss: 0.1137 - val_acc: 0.9811
Epoch 83/100
34/34 [==============================] - 1s 30ms/step - loss: 0.1339 - acc: 0.9752 - val_loss: 0.1184 - val_acc: 0.9811
Epoch 84/100
34/34 [==============================] - 1s 30ms/step - loss: 0.1324 - acc: 0.9793 - val_loss: 0.1232 - val_acc: 0.9759
Epoch 85/100
34/34 [==============================] - 1s 30ms/step - loss: 0.1304 - acc: 0.9793 - val_loss: 0.1161 - val_acc: 0.9811
Epoch 86/100
34/34 [==============================] - 1s 29ms/step - loss: 0.1218 - acc: 0.9766 - val_loss: 0.1199 - val_acc: 0.9811
Epoch 87/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1250 - acc: 0.9802 - val_loss: 0.1088 - val_acc: 0.9822
Epoch 88/100
34/34 [==============================] - 1s 28ms/step - loss: 0.1256 - acc: 0.9793 - val_loss: 0.1392 - val_acc: 0.9727
Epoch 89/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1298 - acc: 0.9808 - val_loss: 0.1162 - val_acc: 0.9822
Epoch 90/100
34/34 [==============================] - 1s 29ms/step - loss: 0.1217 - acc: 0.9798 - val_loss: 0.1092 - val_acc: 0.9822
Epoch 91/100
34/34 [==============================] - 1s 28ms/step - loss: 0.1222 - acc: 0.9821 - val_loss: 0.1178 - val_acc: 0.9822
Epoch 92/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1201 - acc: 0.9814 - val_loss: 0.1210 - val_acc: 0.9780
Epoch 93/100
34/34 [==============================] - 1s 28ms/step - loss: 0.1171 - acc: 0.9835 - val_loss: 0.1198 - val_acc: 0.9811
Epoch 94/100
34/34 [==============================] - 1s 28ms/step - loss: 0.1140 - acc: 0.9859 - val_loss: 0.1130 - val_acc: 0.9864
Epoch 95/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1074 - acc: 0.9867 - val_loss: 0.1110 - val_acc: 0.9853
Epoch 96/100
34/34 [==============================] - 1s 28ms/step - loss: 0.1251 - acc: 0.9812 - val_loss: 0.1241 - val_acc: 0.9832
Epoch 97/100
34/34 [==============================] - 1s 28ms/step - loss: 0.1157 - acc: 0.9826 - val_loss: 0.1147 - val_acc: 0.9822
Epoch 98/100
34/34 [==============================] - 1s 28ms/step - loss: 0.1203 - acc: 0.9825 - val_loss: 0.1199 - val_acc: 0.9790
Epoch 99/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1170 - acc: 0.9833 - val_loss: 0.1355 - val_acc: 0.9822
Epoch 100/100
34/34 [==============================] - 1s 27ms/step - loss: 0.1281 - acc: 0.9798 - val_loss: 0.1042 - val_acc: 0.9874
953/953 [==============================] - 0s 124us/step

Test result: 98.741 loss: 0.104
['Cube', 'Nothing', 'Cube', 'Nothing', 'Star', 'Ball', 'Cube', 'Cube', 'Triangle', 'Cross', 'Hollow Cube', 'Hollow Cube', 'Star', 'Cube', 'Triangle', 'Cross', 'Cube', 'Cube', 'Triangle', 'Cube', 'Cube', 'Cylinder', 'Cube', 'Nothing', 'Star', 'Hollow Cube', 'Cylinder', 'Star', 'Cylinder', 'Ball', 'Star', 'Cross', 'Nothing', 'Star', 'Hollow Cube', 'Cube']
